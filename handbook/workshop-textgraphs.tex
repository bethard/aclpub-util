\sessionabstracts{TextGraphs-8: Graph-based Methods for Natural Language Processing}{Eliza Anderson Amphitheater}{}{
\sessionabstract{Friday}{10:05}{10:20}{Eliza Anderson Amphitheater}{Event-Centered Information Retrieval Using Kernels on Event Graphs}{ Goran Glava\v{s},  Jan \v{S}najder}{Traditional information retrieval models assume keyword-based queries and use unstructured document representations. There is an abundance of event-centered texts (e.g., breaking news) and event-oriented information needs that often involve structure that cannot be expressed using keywords. We present a novel retrieval model that uses a structured event-based representation.  We structure queries and documents as graphs of event mentions and employ  graph kernels to measure the query-document similarity. Experimental results on two event-oriented test collections show significant improvements over state-of-the-art keyword-based models.}
\sessionabstractsep
\sessionabstract{Friday}{10:20}{10:30}{Eliza Anderson Amphitheater}{JoBimText Visualizer: A Graph-based Approach to Contextualizing Distributional Similarity}{ Chris Biemann,  Bonaventura Coppola,  Michael R. Glass,  Alfio Gliozzo,  Matthew Hatem,  Martin Riedl}{We introduce an interactive visualization component for the JoBimText project.  JoBimText is an open source platform for large-scale distributional semantics based on graph representations.  First we describe the underlying technology for computing a distributional thesaurus on words using bipartite graphs of words and context features, and contextualizing the list of semantically similar words towards a given sentential context using graph-based ranking.  Then we demonstrate the capabilities of this contextualized text expansion technology in an interactive visualization. The visualization can be used as a semantic parser providing contextualized expansions of words in text as well as disambiguation to word senses induced by graph clustering, and is provided as an open source tool.}
\sessionabstractsep
\sessionabstract{Friday}{11:00}{11:25}{Eliza Anderson Amphitheater}{Merging Word Senses}{ Sumit Bhagwani,  Shrutiranjan Satapathy,  Harish Karnick}{WordNet, a widely used sense inventory for Word Sense Disambiguation, is often too fine-grained for many Natural Language applications because of its narrow sense distinctions. We present a semi-supervised approach to learn similarity between WordNet synsets using a graph based recursive similarity definition. We seed our framework with sense similarities of all the word-sense pairs, learnt using supervision on human-labelled sense clusterings. Finally we discuss our method to derive coarse sense inventories at arbitrary granularities and show that the coarse grained sense inventory obtained significantly boosts the disambiguation of nouns on standard test sets.}
\sessionabstractsep
\sessionabstract{Friday}{11:25}{11:50}{Eliza Anderson Amphitheater}{Reconstructing Big Semantic Similarity Networks}{ Ai He,  Shefali Sharma,  Chun-Nan Hsu}{Distance metric learning from high (thousands or more) dimensional data with hundreds or thousands of classes is intractable but in NLP and IR, high dimensionality is usually required to represent data points, such as in modeling semantic similarity. This paper presents algorithms to scale up learning of a Mahalanobis distance metric from a large data graph in a high dimensional space. Our novel contributions include random projection that reduces dimensionality and a new objective function that regularizes intra-class and inter-class distances to handle a large number of classes. We show that the new objective function is convex and can be efficiently optimized by a stochastic-batch subgradient descent method. We applied our algorithm to two different domains; semantic similarity of documents collected from the Web, and phenotype descriptions in genomic data. Experiments show that our algorithm can handle the high-dimensional big data and outperform competing approximations in both domains.}
\sessionabstractsep
\sessionabstract{Friday}{11:50}{12:15}{Eliza Anderson Amphitheater}{Graph-Based Unsupervised Learning of Word Similarities Using Heterogeneous Feature Types}{ Avneesh Saluja,  Jiri Navratil}{In this work, we propose a graph-based approach to computing similarities between words in an unsupervised manner, and take advantage of heterogeneous feature types in the process. The approach is based on the creation of two separate graphs, one for words and one for features of different types (alignment- based, orthographic, etc.). The graphs are connected through edges that link nodes in the feature graph to nodes in the word graph, the edge weights representing the importance of a particular feature for a particular word. High quality graphs are learned during training, and the proposed method outperforms experimental baselines.}
\sessionabstractsep
\sessionabstract{Friday}{12:15}{12:30}{Eliza Anderson Amphitheater}{From Global to Local Similarities: A Graph-Based Contextualization Method using Distributional Thesauri}{ Martin Riedl,  Chris Biemann}{After recasting the computation of a distributional thesaurus in a graph-based framework for term similarity, we introduce a new contextualization method that generates, for each term occurrence in a text, a ranked list of terms that are semantically similar and compatible with the given context. The framework is instantiated by the definition of term and context, which we derive from dependency parses in this work.  Evaluating our approach on a standard data set for lexical substitution, we show substantial improvements over a strong non-contextualized baseline across all parts of speech.  In contrast to comparable approaches, our framework defines an unsupervised generative method for similarity in context and does not rely on the existence of lexical resources as a source for candidate expansions.}
\sessionabstractsep
\sessionabstract{Friday}{3:05}{3:30}{Eliza Anderson Amphitheater}{Understanding seed selection in bootstrapping}{ Yo Ehara,  Issei Sato,  Hidekazu Oiwa,  Hiroshi Nakagawa}{Bootstrapping has recently become the focus of much attention in natural language processing to reduce labeling cost. In bootstrapping, unlabeled instances can be harvested from the initial labeled ``seed'' set. The selected seed set affects accuracy, but how to select a good seed set is not yet clear. Thus, an ``iterative seeding'' framework is proposed for bootstrapping to reduce its labeling cost. Our framework iteratively selects the unlabeled instance that has the best ``goodness of seed'' and labels the unlabeled instance in the seed set. Our framework deepens understanding of this seeding process in bootstrapping by deriving the dual problem. We propose a method called expected model rotation (EMR) that works well on not well-separated data which frequently occur as realistic data. Experimental results show that EMR can select seed sets that provide significantly higher mean reciprocal rank on realistic data than existing naive selection methods or random seed sets.}
\sessionabstractsep
\sessionabstract{Friday}{4:00}{4:25}{Eliza Anderson Amphitheater}{Graph-Structures Matching for Review Relevance Identification}{ Lakshmi Ramachandran,  Edward Gehringer}{Review quality is determined by identifying the relevance of a review to a submission (the article or paper the review was written for). We identify relevance in terms of the semantic and syntactic similarities between two texts. We use a word order graph, whose vertices, edges and double edges help determine structure-based match across texts. We use WordNet to determine semantic relatedness. Ours is a lexico-semantic approach, which predicts relevance with an accuracy of 66\% and f-measure of 0.67.}
\sessionabstractsep
\sessionabstract{Friday}{4:25}{4:50}{Eliza Anderson Amphitheater}{Automatic Extraction of Reasoning Chains from Textual Reports}{ Gleb Sizov,  Pinar \"{O}zt\"{u}rk}{Many organizations possess large collections of textual reports that document how a problem is solved or analysed, e.g. medical patient records, industrial accident reports, lawsuit records and investigation reports. Effective use of expert knowledge contained in these reports may greatly increase productivity of the organization. In this article, we propose a method for automatic extraction of reasoning chains that contain information used by the author of a report to analyse the problem at hand. For this purpose, we developed a graph-based text representation that makes the relations between textual units explicit. This representation is acquired automatically from a report using natural language processing tools including syntactic and discourse parsers. When applied to aviation investigation reports, our method generates reasoning chains that reveal the connection between initial information about the aircraft incident and its causes.}
\sessionabstractsep
\sessionabstract{Friday}{4:50}{5:15}{Eliza Anderson Amphitheater}{Graph-based Approaches for Organization Entity Resolution in MapReduce}{ Hakan Kardes,  Deepak Konidena,  Siddharth Agrawal,  Micah Huff,  Ang Sun}{Entity Resolution is the task of identifying which records in a database refer to the same entity.  A standard machine learning pipeline for the entity resolution problem consists of three major components: blocking, pairwise linkage, and clustering. The blocking step groups records by shared properties to determine which pairs of records should be examined by the pairwise linker as potential duplicates. Next, the linkage step assigns a probability score to pairs of records inside each block. If a pair scores above a user-defined threshold, the records are presumed to represent the same entity. Finally, the clustering step turns the input records into clusters of records (or profiles), where each cluster is uniquely associated with a single real-world entity. This paper describes the blocking and clustering strategies used to deploy a massive database of organization entities to power a major commercial People Search Engine. We demonstrate the viability of these algorithms for large data sets on a 50-node hadoop cluster.}
\sessionabstractsep
\sessionabstract{Friday}{5:15}{5:40}{Eliza Anderson Amphitheater}{A Graph-Based Approach to Skill Extraction from Text}{ Ilkka Kivim\"{a}ki,  Alexander Panchenko,  Adrien Dessy,  Dries Verdegem,  Pascal Francq,  Hugues Bersini,  Marco Saerens}{This paper presents a system, that performs skill extraction from text documents. It outputs a list of professional skills that are relevant to a given input text. We argue that the system can be practical for hiring and management of personnel in an organization. We make use of the texts and hyperlink graph of Wikipedia, as well as a list of professional skills obtained from the LinkedIn social network.}
}
